{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for random distributions:\n",
    "from scipy.stats import norm, poisson\n",
    "\n",
    "# for logistic regression:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plotting Functions\n",
    "\n",
    "def rasterplot(spikes,movement,trial):\n",
    "\n",
    "  [movements, trials, neurons, timepoints] = np.shape(spikes)\n",
    "\n",
    "  trial_spikes = spikes[movement,trial, :, :]\n",
    "\n",
    "  trial_events = [((trial_spikes[x,:] > 0).nonzero()[0]-150)/100 for x in range(neurons)]\n",
    "\n",
    "  plt.figure()\n",
    "  dt=1/100\n",
    "  plt.eventplot(trial_events, linewidths=1);\n",
    "  plt.title('movement: %d - trial: %d'%(movement, trial))\n",
    "  plt.ylabel('neuron')\n",
    "  plt.xlabel('time [s]')\n",
    "  plt.show()\n",
    "\n",
    "def plotCrossValAccuracies(accuracies):\n",
    "  f, ax = plt.subplots(figsize=(8, 3))\n",
    "  ax.boxplot(accuracies, vert=False, widths=.7)\n",
    "  ax.scatter(accuracies, np.ones(8))\n",
    "  ax.set(xlabel=\"Accuracy\", yticks=[],\n",
    "         title=f\"Average test accuracy: {accuracies.mean():.2%}\")\n",
    "  ax.spines[\"left\"].set_visible(False)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Generate Data\n",
    "\n",
    "def generateSpikeTrains():\n",
    "\n",
    "  gain = 2\n",
    "  neurons = 50\n",
    "  movements = [0, 1, 2]\n",
    "  repetitions = 800\n",
    "\n",
    "  np.random.seed(37)\n",
    "\n",
    "  # set up the basic parameters:\n",
    "  dt = 1/100\n",
    "  start, stop = -1.5, 1.5\n",
    "  t = np.arange(start, stop+dt, dt)  # a time interval\n",
    "  Velocity_sigma = 0.5  # std dev of the velocity profile\n",
    "  Velocity_Profile = norm.pdf(t, 0, Velocity_sigma)/norm.pdf(0, 0, Velocity_sigma)  # The Gaussian velocity profile, normalized to a peak of 1\n",
    "\n",
    "  # set up the neuron properties:\n",
    "  Gains = np.random.rand(neurons) * gain  # random sensitivity between 0 and `gain`\n",
    "  FRs = (np.random.rand(neurons) * 60 ) - 10  # random base firing rate between -10 and 50\n",
    "\n",
    "  # output matrix will have this shape:\n",
    "  target_shape = [len(movements), repetitions, neurons, len(Velocity_Profile)]\n",
    "\n",
    "  # build matrix for spikes, first, they depend on the velocity profile:\n",
    "  Spikes = np.repeat(Velocity_Profile.reshape([1, 1, 1, len(Velocity_Profile)]),\n",
    "                     len(movements)*repetitions*neurons,axis=2).reshape(target_shape)\n",
    "\n",
    "  # multiplied by gains:\n",
    "  S_gains = np.repeat(np.repeat(Gains.reshape([1, 1, neurons]), len(movements)*repetitions, axis=1).reshape(target_shape[:3]),\n",
    "                      len(Velocity_Profile)).reshape(target_shape)\n",
    "  Spikes = Spikes * S_gains\n",
    "\n",
    "  # and multiplied by the movement:\n",
    "  S_moves = np.repeat( np.array(movements).reshape([len(movements), 1, 1, 1]),\n",
    "                      repetitions*neurons*len(Velocity_Profile), axis=3 ).reshape(target_shape)\n",
    "  Spikes = Spikes * S_moves\n",
    "\n",
    "  # on top of a baseline firing rate:\n",
    "  S_FR = np.repeat(np.repeat(FRs.reshape([1, 1, neurons]),\n",
    "                             len(movements)*repetitions, axis=1).reshape(target_shape[:3]),\n",
    "                   len(Velocity_Profile)).reshape(target_shape)\n",
    "  Spikes = Spikes + S_FR\n",
    "\n",
    "  # can not run the poisson random number generator on input lower than 0:\n",
    "  Spikes = np.where(Spikes < 0, 0, Spikes)\n",
    "\n",
    "  # so far, these were expected firing rates per second, correct for dt:\n",
    "  Spikes = poisson.rvs(Spikes * dt)\n",
    "\n",
    "  return(Spikes)\n",
    "\n",
    "\n",
    "def subsetPerception(spikes):\n",
    "\n",
    "  movements = [0, 1, 2]\n",
    "  split = 400\n",
    "  subset = 40\n",
    "  hwin = 3\n",
    "\n",
    "  [num_movements, repetitions, neurons, timepoints] = np.shape(spikes)\n",
    "\n",
    "  decision = np.zeros([num_movements, repetitions])\n",
    "\n",
    "  # ground truth for logistic regression:\n",
    "  y_train = np.repeat([0, 1, 1],split)\n",
    "  y_test = np.repeat([0, 1, 1],repetitions-split)\n",
    "\n",
    "  m_train = np.repeat(movements, split)\n",
    "  m_test = np.repeat(movements, split)\n",
    "\n",
    "  # reproduce the time points:\n",
    "  dt = 1/100\n",
    "  start, stop = -1.5, 1.5\n",
    "  t = np.arange(start, stop+dt, dt)\n",
    "\n",
    "  w_idx = list( (abs(t) < (hwin*dt)).nonzero()[0] )\n",
    "  w_0 = min(w_idx)\n",
    "  w_1 = max(w_idx)+1  # python...\n",
    "\n",
    "  # get the total spike counts from stationary and movement trials:\n",
    "  spikes_stat = np.sum( spikes[0, :, :, :], axis=2)\n",
    "  spikes_move = np.sum( spikes[1:, :, :, :], axis=3)\n",
    "\n",
    "  train_spikes_stat = spikes_stat[:split, :]\n",
    "  train_spikes_move = spikes_move[:, :split, :].reshape([-1, neurons])\n",
    "\n",
    "  test_spikes_stat = spikes_stat[split:, :]\n",
    "  test_spikes_move = spikes_move[:, split:, :].reshape([-1, neurons])\n",
    "\n",
    "  # data to use to predict y:\n",
    "  x_train = np.concatenate((train_spikes_stat, train_spikes_move))\n",
    "  x_test  = np.concatenate((test_spikes_stat, test_spikes_move))\n",
    "\n",
    "  # this line creates a logistics regression model object, and immediately fits it:\n",
    "  population_model = LogisticRegression(solver='liblinear', random_state=0).fit(x_train, y_train)\n",
    "\n",
    "  # solver, one of: 'liblinear', 'newton-cg', 'lbfgs', 'sag', and 'saga'\n",
    "  # some of those require certain other options\n",
    "  #print(population_model.coef_)       # slope\n",
    "  #print(population_model.intercept_)  # intercept\n",
    "\n",
    "  ground_truth = np.array(population_model.predict(x_test))\n",
    "  ground_truth = ground_truth.reshape([3, -1])\n",
    "\n",
    "  output = {}\n",
    "  output['perception'] = ground_truth\n",
    "  output['spikes'] = spikes[:, split:, :subset, :]\n",
    "\n",
    "  return(output)\n",
    "\n",
    "\n",
    "def getData():\n",
    "\n",
    "  spikes = generateSpikeTrains()\n",
    "\n",
    "  dataset = subsetPerception(spikes=spikes)\n",
    "\n",
    "  return(dataset)\n",
    "\n",
    "\n",
    "dataset = getData()\n",
    "perception = dataset['perception']\n",
    "spikes = dataset['spikes']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
